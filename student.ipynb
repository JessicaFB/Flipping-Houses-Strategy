{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Jessica Forrest-Baldini\n",
    "* Student pace: Part-time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime as date\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('kc_house_data.csv') \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Drop waterfront - only 146 homes with waterfronts\n",
    "# Drop view - this represent if the property has been viewed\n",
    "# Drop id\n",
    "\n",
    "to_drop = ['waterfront','view','id']\n",
    "df = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0\n",
       "price               0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "sqft_living         0\n",
       "sqft_lot            0\n",
       "floors              0\n",
       "condition           0\n",
       "grade               0\n",
       "sqft_above          0\n",
       "sqft_basement       0\n",
       "yr_built            0\n",
       "yr_renovated     3842\n",
       "zipcode             0\n",
       "lat                 0\n",
       "long                0\n",
       "sqft_living15       0\n",
       "sqft_lot15          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since not all homes have been renovated, I'm going to replace the 'NaN' values for \n",
    "# 'yr_renovated' with '0'\n",
    "df.yr_renovated = df.yr_renovated.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN basement values with 0 as there are only 454 of them \n",
    "# Test median values for these later to see if it improves model\n",
    "\n",
    "df.sqft_basement = df.sqft_basement.replace('?','0.0').astype(float)\n",
    "#df.sqft_basement = df.sqft_basement+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take abs of longitude for normalization later on\n",
    "df.long = abs(df.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "      <td>21597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>540297.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>15099.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98078.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>12758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>367368.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>27274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98001.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>322000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98033.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>5100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>7618.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98065.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>7620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>645000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98118.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>10083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>7700000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13540.0</td>\n",
       "      <td>1651359.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9410.0</td>\n",
       "      <td>4820.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>98199.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6210.0</td>\n",
       "      <td>871200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living   sqft_lot   floors  \\\n",
       "count    21597.0   21597.0    21597.0      21597.0    21597.0  21597.0   \n",
       "mean    540297.0       3.0        2.0       2080.0    15099.0      1.0   \n",
       "std     367368.0       1.0        1.0        918.0    41413.0      1.0   \n",
       "min      78000.0       1.0        0.0        370.0      520.0      1.0   \n",
       "25%     322000.0       3.0        2.0       1430.0     5040.0      1.0   \n",
       "50%     450000.0       3.0        2.0       1910.0     7618.0      2.0   \n",
       "75%     645000.0       4.0        2.0       2550.0    10685.0      2.0   \n",
       "max    7700000.0      33.0        8.0      13540.0  1651359.0      4.0   \n",
       "\n",
       "       condition    grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "count    21597.0  21597.0     21597.0        21597.0   21597.0       21597.0   \n",
       "mean         3.0      8.0      1789.0          286.0    1971.0          69.0   \n",
       "std          1.0      1.0       828.0          440.0      29.0         364.0   \n",
       "min          1.0      3.0       370.0            0.0    1900.0           0.0   \n",
       "25%          3.0      7.0      1190.0            0.0    1951.0           0.0   \n",
       "50%          3.0      7.0      1560.0            0.0    1975.0           0.0   \n",
       "75%          4.0      8.0      2210.0          550.0    1997.0           0.0   \n",
       "max          5.0     13.0      9410.0         4820.0    2015.0        2015.0   \n",
       "\n",
       "       zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "count  21597.0  21597.0  21597.0        21597.0     21597.0  \n",
       "mean   98078.0     48.0    122.0         1987.0     12758.0  \n",
       "std       54.0      0.0      0.0          685.0     27274.0  \n",
       "min    98001.0     47.0    121.0          399.0       651.0  \n",
       "25%    98033.0     47.0    122.0         1490.0      5100.0  \n",
       "50%    98065.0     48.0    122.0         1840.0      7620.0  \n",
       "75%    98118.0     48.0    122.0         2360.0     10083.0  \n",
       "max    98199.0     48.0    123.0         6210.0    871200.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that bedrooms has what seems to be a major outlier, 33 bedrooms. Let's take a deeper look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8748</td>\n",
       "      <td>8/21/2014</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3000</td>\n",
       "      <td>4960</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2400</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1918</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>98106</td>\n",
       "      <td>47.5560</td>\n",
       "      <td>122.363</td>\n",
       "      <td>1420</td>\n",
       "      <td>4960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13301</td>\n",
       "      <td>8/14/2014</td>\n",
       "      <td>1150000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4590</td>\n",
       "      <td>10920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2500</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.5861</td>\n",
       "      <td>122.113</td>\n",
       "      <td>2730</td>\n",
       "      <td>10400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15147</td>\n",
       "      <td>10/29/2014</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3610</td>\n",
       "      <td>11914</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3010</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5705</td>\n",
       "      <td>122.175</td>\n",
       "      <td>2040</td>\n",
       "      <td>11914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15856</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>640000.0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1620</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1040</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6878</td>\n",
       "      <td>122.331</td>\n",
       "      <td>1330</td>\n",
       "      <td>4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19239</td>\n",
       "      <td>12/29/2014</td>\n",
       "      <td>660000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2920</td>\n",
       "      <td>3745</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1860</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98105</td>\n",
       "      <td>47.6635</td>\n",
       "      <td>122.320</td>\n",
       "      <td>1810</td>\n",
       "      <td>3745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "8748    8/21/2014   520000.0        11       3.00         3000      4960   \n",
       "13301   8/14/2014  1150000.0        10       5.25         4590     10920   \n",
       "15147  10/29/2014   650000.0        10       2.00         3610     11914   \n",
       "15856   6/25/2014   640000.0        33       1.75         1620      6000   \n",
       "19239  12/29/2014   660000.0        10       3.00         2920      3745   \n",
       "\n",
       "       floors  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "8748      2.0          3      7        2400          600.0      1918   \n",
       "13301     1.0          3      9        2500         2090.0      2008   \n",
       "15147     2.0          4      7        3010          600.0      1958   \n",
       "15856     1.0          5      7        1040          580.0      1947   \n",
       "19239     2.0          4      7        1860         1060.0      1913   \n",
       "\n",
       "       yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "8748         1999.0    98106  47.5560  122.363           1420        4960  \n",
       "13301           0.0    98004  47.5861  122.113           2730       10400  \n",
       "15147           0.0    98006  47.5705  122.175           2040       11914  \n",
       "15856           0.0    98103  47.6878  122.331           1330        4700  \n",
       "19239           0.0    98105  47.6635  122.320           1810        3745  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with other homes in data set that have high number of bedrooms\n",
    "df[df.bedrooms > 9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 33 bedrooms and only 1.75 bathrooms doesn't seem right. It is a pretty big lot at 6,000sqft\n",
    "# but 33 bedrooms doesn't seem right. Remove. \n",
    "\n",
    "to_drop = df[df.bedrooms == 33].index\n",
    "df = df.drop(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see price has some big outliers as well, as the 75th percentile is \\\\$ 645,000 and they max is \\\\$ 7,700,000, which is \\\\$ 7M more. \n",
    "\n",
    "Let's take a closer look at the percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, df.price.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to remove the bottom and top percentile to remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_tot = len(df)\n",
    "df = df[(df.price > 154000.0) & (df.price < 1970000.0)] # Subsetting to remove extreme outliers\n",
    "print('Percent removed:', (orig_tot -len(df))/orig_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, df.sqft_lot.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_tot = len(df)\n",
    "df = df[(df.sqft_lot > 1010.61) & (df.sqft_lot < 213008.0)] # Subsetting to remove extreme outliers\n",
    "print('Percent removed:', (orig_tot -len(df))/orig_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.sqft_basement.describe())\n",
    "#df.sqft_basement.value_counts()\n",
    "#df[df.sqft_basement > 100].sort_values(by='sqft_basement', ascending=True).head(20)\n",
    "print(sum(df.sqft_basement > 0))\n",
    "#sns.regplot(df.sqft_basement,df.price);\n",
    "sns.regplot(df[df.sqft_basement >= 110].sqft_basement,df[df.sqft_basement >= 110].price);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 8,317 of the 32,000+ homes have basements, so we're going to bin them. I used zero as one bin and then did a quartile split for all the 'sqft_basement' values for homes with basements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Bin 'sqft_basement' starting at the min square footage for homes with a basement\n",
    "# bins = pd.qcut(df.sqft_basement[df.sqft_basement >= 110],q=4)\n",
    "# bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Bin sqft_basement\n",
    "\n",
    "bins_sqft_basement = [0,109,450,980,5000]\n",
    "\n",
    "# Bin data & return dummies\n",
    "def binned_dummies(data, features, bins):\n",
    "    data_bins = pd.cut(data, bins)\n",
    "    data_bins = data_bins.cat.as_unordered()\n",
    "    dummies = pd.get_dummies(data_bins, prefix = features, drop_first=True)\n",
    "    return dummies\n",
    "\n",
    "dummies_sqft_basement = binned_dummies(df.sqft_basement,'sqft_basement', bins_sqft_basement)\n",
    "\n",
    "# Remove original column from data set\n",
    "df = df.drop(['sqft_basement'], axis=1)\n",
    "                                            \n",
    "# Add new columns in\n",
    "df = pd.concat([df, dummies_sqft_basement], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plt.hist(df.grade);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df.condition);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.condition.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df.long);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert datestr to datenum\n",
    "def datenum(datestr):\n",
    "    '''\n",
    "    Convert datestring in the format MM/DD/YYYY\n",
    "    to MATLAB style datenum\n",
    "    '''\n",
    "    datenum = date.toordinal(date((int(datestr.split('/', -1)[2])),\n",
    "                                  (int(datestr.split('/', -1)[0])),\n",
    "                                  (int(datestr.split('/', -1)[1]))\n",
    "                                 ))+366\n",
    "    return datenum\n",
    "\n",
    "# Apply to date column\n",
    "df.date = df.date.map(datenum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data and check for any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round(df.describe(),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sqft_lot' seems to have a major outlier at 1,651,359 sqft. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# print(df.sqft_lot.median())\n",
    "# display(df.sort_values(by='sqft_lot', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be the highest, but not necessarily an outlier. Let's go ahead and leave it for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.long.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df.long);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize, MinMax Scale, Standardize, \n",
    "One-Hot Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check for normality, heteroscedasticity & discover categorical data. Can get a good idea of categorical features from looking at the data above, but let's explore normality, categorical and any relationships using a pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because takes a long time to run\n",
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 'condition' and 'grade' are technically categorical, they are on a scale, so I am going to leave them as is, and will min-max scale them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "\n",
    "# Log Transform \n",
    "\n",
    "# Continuous variables\n",
    "features = ['date','price','sqft_living','lat','long','bedrooms','bathrooms','floors','condition','grade',\n",
    "            'sqft_lot','sqft_above','yr_built',\n",
    "            'sqft_living15','sqft_lot15','zipcode']\n",
    "\n",
    "df_cont_features = df[features]\n",
    "\n",
    "# Add '_log' to continuous variable column names\n",
    "log_names = [f'{column}_log' for column in df_cont_features.columns]\n",
    "\n",
    "# Log transform continuous variables\n",
    "df_log = np.log(df_cont_features)\n",
    "df_log.columns = log_names\n",
    "\n",
    "\n",
    "### Normalize (subract mean and divide by std)\n",
    "\n",
    "# Define function to normalize\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "# Apply function to normalize\n",
    "df_log_norm = df_log.apply(normalize)\n",
    "\n",
    "# # Define function to min-max scale\n",
    "# def minmaxscale(feature):\n",
    "#     return (feature-min(feature))/(max(feature)-min(feature))\n",
    "\n",
    "# # Apply function to min-max scale\n",
    "# df_log_norm_scale = df_log.apply(minmaxscale)\n",
    "\n",
    "# Remove original column from data set\n",
    "df = df.drop(features, axis=1)\n",
    "\n",
    "# Add new columns in\n",
    "df = pd.concat([df, df_log_norm], axis=1) #_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Take a look at the correlation matrix to check for multicollinearity\n",
    "abs(df.corr()) > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Check & see if sqft_lot15 & sqft_living15 are correlated with sqft_lot & sqft_living\n",
    "# sns.regplot(df.sqft_lot,df.sqft_lot15)\n",
    "# plt.show()\n",
    "# sns.regplot(df.sqft_living,df.sqft_living15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 'sqft_lot15' & 'sqft_living15' are correlated with 'sqft_lot' & 'sqft_living', which makes sense because the features appended with 15 represent the average of the 15 nearest neighbors. \n",
    "\n",
    "We will remove these values to prevent multicollinearity in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Remove sqft_lot15 & sqft_living15\n",
    "# df = df.drop(['sqft_lot15','sqft_living15'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Take a look at the correlation matrix to check for multicollinearity\n",
    "# df.corr() > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that 'sqft_living' seems to be highly correlated with multiple features such as 'bathrooms', 'grade', and 'sqft_above'. 'sqft_living' represents the square footage of the entire home and seems that it would be a strong indicator of home price. The squarefoot of other features are essentially subsets of the overall home squarefootage. So for now I am going to remove it. However, it could be kept in place and other features removed later on to see if this improves the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Remove 'sqft_living' to prevent multicollinearity \n",
    "# # as it is highly correlated with multiple features\n",
    "\n",
    "# df = df.drop(['sqft_living'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs(df.corr()) > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 'sqft_above' and 'grade' are highly correlated, so we should only keep one to prevent multicollinearity. \n",
    "\n",
    "For now I'm going to keep 'sqft_above', but can also test removing 'sqft_above' and one-hot-encoding 'grade' later on to see if it improves performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # We can see the relationship here between 'sqft_above' and 'grade', it appears to possibly\n",
    "# # be polynomial. While grade is categorical, it is continuous\n",
    "# sns.regplot(df.grade,df.sqft_above);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the relationship looks slightly polynomial, and 'grade' technically is categorical, I want to look at their distributions to further explore the relationship. Let's look at the histograms/distplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# sns.distplot(df.sqft_above)\n",
    "# plt.show()\n",
    "# plt.hist(df.grade)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both do appear to be skewed in the same direction, so perhaps they are linearly related. Okay, I will remove grade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['grade'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and feature variables\n",
    "\n",
    "X = df.drop(['price_log'],axis=1)\n",
    "y = df.price_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data with test size of 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the linear regression model class\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model to train data\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions on test set\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Test Errors Results\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring=mse)\n",
    "cv_5_results\n",
    "\n",
    "\n",
    "print(f\"RMSE: {np.sqrt(cv_5_results.mean())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "crossval = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "baseline_R2 = np.mean(cross_val_score(linreg, X, y, scoring='r2', cv=crossval))\n",
    "baseline_R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodel (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Find top interactions by R^2 value\n",
    "\n",
    "# Use combinations from itertools to create all possible combinations of two features\n",
    "feat_combinations = combinations(X_train.columns, 2)\n",
    "\n",
    "# Empty list to fill for interactons values\n",
    "interactions = []\n",
    "\n",
    "# for i, (feature1,feature2) in feature_combinations:\n",
    "for i, (a, b) in enumerate(feat_combinations):\n",
    "    # fill interatctions list with feature a * feature b\n",
    "    X_train['interaction'] = X_train[a] * X_train[b]\n",
    "    R2 = np.mean(cross_val_score(linreg, X_train, y_train, scoring='r2', cv=crossval))\n",
    "    if R2 > baseline_R2:\n",
    "        interactions.append((a, b, round(R2,5)))\n",
    "            \n",
    "print('Top 3 interactions: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Performing Model - So Far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a final model with interactions\n",
    "#Use 10-fold cross-validation to build a model using the above interaction.\n",
    "\n",
    "crossval = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "final = X.copy()\n",
    "\n",
    "final['lat_log*sqft_lot15_log'] = final['lat_log'] * final['sqft_lot15_log']\n",
    "#final['lat_log*sqft_lot_log'] = final['lat_log'] * final['sqft_lot_log']\n",
    "final['long_log*zipcode_log'] = final['long_log'] * final['zipcode_log']\n",
    "\n",
    "final_model_R2 = np.mean(cross_val_score(linreg, final, y, scoring='r2', cv=crossval))\n",
    "\n",
    "print(final_model_R2)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "df_inter_sm = sm.add_constant(final)\n",
    "model = sm.OLS(y,final)\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Errors Results\n",
    "cv_5_results = cross_val_score(linreg, final, y, cv=5, scoring=mse)\n",
    "cv_5_results\n",
    "\n",
    "\n",
    "print(f\"RMSE: {np.sqrt(cv_5_results.mean())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(results.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
